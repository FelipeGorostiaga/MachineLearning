{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "looking-island",
   "metadata": {},
   "source": [
    "## AdmisiÃ³n en la universidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import file\n",
    "df = pd.read_csv('../../res/tp1/binary.csv', sep=',') # columns: admit, gre, gpa, rank; 399 rows\n",
    "row_count = df.shape[0]\n",
    "rank_count = df['rank'].value_counts().sort_values()\n",
    "ranks = np.sort(rank_count.index.values)\n",
    "first_level_fields = {'gre': ['>= 500', '< 500'], 'gpa': ['>= 3', '< 3']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "raising-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for each rank:\n",
      "1    0.153465\n",
      "4    0.168317\n",
      "3    0.301980\n",
      "2    0.376238\n",
      "Name: rank, dtype: float64\n",
      "\n",
      "GRE:\n",
      "     >= 500     < 500\n",
      "1  0.809524  0.190476\n",
      "2  0.810458  0.189542\n",
      "3  0.788618  0.211382\n",
      "4  0.782609  0.217391\n",
      "\n",
      "GPA:\n",
      "       >= 3       < 3\n",
      "1  0.857143  0.142857\n",
      "2  0.823529  0.176471\n",
      "3  0.829268  0.170732\n",
      "4  0.797101  0.202899\n"
     ]
    }
   ],
   "source": [
    "rank_probabilities = rank_count.apply(lambda x: (x + 1) / (row_count + len(ranks)))  # P(rank_i)\n",
    "print(f'Probability for each rank:\\n{rank_probabilities}')\n",
    "fields_rank_probabilities = {key: {} for key in first_level_fields.keys()} # {'gre':{}, 'gpa':{}}\n",
    "for rank in ranks:\n",
    "    rank_rows = df.query(f'rank == {rank}')\n",
    "    for field, rng in first_level_fields.items():\n",
    "        fields_rank_probabilities[field][rank] = []\n",
    "        upper_matching = rank_rows.query(f'{field} {rng[0]}') # e.g. 'gre >= 500'\n",
    "        # Chequear si es necesario Laplace\n",
    "        fields_rank_probabilities[field][rank].append(len(upper_matching) / len(rank_rows)) # len(gre >= 500 and rank) / len(rank)\n",
    "        fields_rank_probabilities[field][rank].append((len(rank_rows) - len(upper_matching)) / len(rank_rows)) # gre < 500\n",
    "\n",
    "# {'gre': {1: [upper, lower], 2: [upper, lower], ...}, 'gpa': {1: [upper, lower], 2: [upper, lower], ...}}\n",
    "gre_table = pd.DataFrame.from_dict(fields_rank_probabilities['gre'], orient='index', columns=first_level_fields['gre'])\n",
    "gpa_table = pd.DataFrame.from_dict(fields_rank_probabilities['gpa'], orient='index', columns=first_level_fields['gpa'])\n",
    "print(f'\\nGRE:\\n{gre_table}')\n",
    "print(f'\\nGPA:\\n{gpa_table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "backed-traffic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1; GRE: >= 500; GPA: >= 3; rows: 47; admission probability: 0.5531914893617021\n",
      "Rank: 1; GRE: >= 500; GPA: < 3; rows: 3; admission probability: 1.0\n",
      "Rank: 1; GRE: < 500; GPA: >= 3; rows: 6; admission probability: 0.5\n",
      "Rank: 1; GRE: < 500; GPA: < 3; rows: 5; admission probability: 0.2\n",
      "Rank: 2; GRE: >= 500; GPA: >= 3; rows: 104; admission probability: 0.4230769230769231\n",
      "Rank: 2; GRE: >= 500; GPA: < 3; rows: 19; admission probability: 0.15789473684210525\n",
      "Rank: 2; GRE: < 500; GPA: >= 3; rows: 21; admission probability: 0.19047619047619047\n",
      "Rank: 2; GRE: < 500; GPA: < 3; rows: 7; admission probability: 0.42857142857142855\n",
      "Rank: 3; GRE: >= 500; GPA: >= 3; rows: 85; admission probability: 0.24705882352941178\n",
      "Rank: 3; GRE: >= 500; GPA: < 3; rows: 11; admission probability: 0.36363636363636365\n",
      "Rank: 3; GRE: < 500; GPA: >= 3; rows: 16; admission probability: 0.1875\n",
      "Rank: 3; GRE: < 500; GPA: < 3; rows: 9; admission probability: 0.0\n",
      "Rank: 4; GRE: >= 500; GPA: >= 3; rows: 44; admission probability: 0.20454545454545456\n",
      "Rank: 4; GRE: >= 500; GPA: < 3; rows: 9; admission probability: 0.1111111111111111\n",
      "Rank: 4; GRE: < 500; GPA: >= 3; rows: 10; admission probability: 0.2\n",
      "Rank: 4; GRE: < 500; GPA: < 3; rows: 4; admission probability: 0.0\n",
      "\n",
      "{'rank == 1 and gre >= 500 and gpa >= 3': [0.5531914893617021, 0.44680851063829785], 'rank == 1 and gre >= 500 and gpa < 3': [1.0, 0.0], 'rank == 1 and gre < 500 and gpa >= 3': [0.5, 0.5], 'rank == 1 and gre < 500 and gpa < 3': [0.2, 0.8], 'rank == 2 and gre >= 500 and gpa >= 3': [0.4230769230769231, 0.5769230769230769], 'rank == 2 and gre >= 500 and gpa < 3': [0.15789473684210525, 0.8421052631578947], 'rank == 2 and gre < 500 and gpa >= 3': [0.19047619047619047, 0.8095238095238095], 'rank == 2 and gre < 500 and gpa < 3': [0.42857142857142855, 0.5714285714285714], 'rank == 3 and gre >= 500 and gpa >= 3': [0.24705882352941178, 0.7529411764705882], 'rank == 3 and gre >= 500 and gpa < 3': [0.36363636363636365, 0.6363636363636364], 'rank == 3 and gre < 500 and gpa >= 3': [0.1875, 0.8125], 'rank == 3 and gre < 500 and gpa < 3': [0.0, 1.0], 'rank == 4 and gre >= 500 and gpa >= 3': [0.20454545454545456, 0.7954545454545454], 'rank == 4 and gre >= 500 and gpa < 3': [0.1111111111111111, 0.8888888888888888], 'rank == 4 and gre < 500 and gpa >= 3': [0.2, 0.8], 'rank == 4 and gre < 500 and gpa < 3': [0.0, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "# Necesitamos P(admit | rank, GRE, GPA) y probabilidad conjunta P(X1, X2, ..., Xn)\n",
    "\n",
    "admission_probabilities = {}\n",
    "for rank in ranks:\n",
    "    # gre_row = gre_table.loc[rank]\n",
    "    # gpa_row = gpa_table.loc[rank]\n",
    "    for gre_class in gre_table.columns:\n",
    "        # p_gre = gre_row[gre_class]\n",
    "        for gpa_class in gpa_table.columns:\n",
    "            row_criteria = f'rank == {rank} and gre {gre_class} and gpa {gpa_class}'\n",
    "            criteria_rows = df.query(row_criteria)\n",
    "            row_criteria_admissions = criteria_rows[criteria_rows.admit == 1]\n",
    "            admission_probabilities[row_criteria] = []\n",
    "            admission_probabilities[row_criteria].append(len(row_criteria_admissions) / len(criteria_rows))\n",
    "            admission_probabilities[row_criteria].append((len(criteria_rows) - len(row_criteria_admissions)) / len(criteria_rows))\n",
    "            # p_gpa = gpa_row[gpa_class]\n",
    "            # p = p_gre * p_gpa\n",
    "            # admission_probabilities[row_criteria].append(p)\n",
    "            print(f'Rank: {rank}; GRE: {gre_class}; GPA: {gpa_class}; rows: {len(criteria_rows)}; admission probability: {admission_probabilities[row_criteria][0]}')\n",
    "\n",
    "print(f'\\n{admission_probabilities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-merchandise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
